{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_age.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/MyDrive/Face Age Regression/dataset'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihI7vdq6EePu",
        "outputId": "bb782b4f-4525-41fe-ad7a-ce5bc192ee89"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1CicvpTOJTS5QdXTfCskdYDicM1Cq3ds3/Face Age Regression/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAC9jrlbzBuP",
        "outputId": "4362e1ad-e3fa-497c-faba-723b17c6f679"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q kaggle\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "GxVsWlbqF9O5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1W-O-sIZET9G"
      },
      "outputs": [],
      "source": [
        "# !kaggle datasets download -d jangedoo/utkface-new\n",
        "# !unzip utkface-new.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "# from tensorflow.keras.layers import Conv2D,MaxPooling2D,Activation,Dropout,Flatten,Dense\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# import tensorflow as tf\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "9ynYIi1aGP2c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hyper parameters**"
      ],
      "metadata": {
        "id": "Lo7yT8F2GgF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=20\n",
        "width=height=224\n",
        "batch_size=1\n",
        "lr=0.001"
      ],
      "metadata": {
        "id": "Elj1vrf9GfZY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "mWEov-kaGtj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images=[]  #X\n",
        "ages=[]    #Y\n",
        "\n",
        "for image_name in os.listdir('crop_part1')[:9000]:\n",
        "  parts=image_name.split('_')\n",
        "  ages.append(int(parts[0]))\n",
        "\n",
        "  image=cv2.imread(f'crop_part1/{image_name}')\n",
        "  image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "  images.append(image)"
      ],
      "metadata": {
        "id": "jWIgv6HPGwDb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images=pd.Series(images,name='Images')\n",
        "ages=pd.Series(ages,name='Ages')\n",
        "df=pd.concat([images,ages],axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "JJIYxfomHR17",
        "outputId": "f43d71f5-e2bb-4210-aada-cf55f0a148a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-166e686f-9fc5-4eef-9b8d-3d9101159ece\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Images</th>\n",
              "      <th>Ages</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[179, 149, 111], [184, 154, 116], [192, 162,...</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[85, 91, 91], [83, 89, 89], [80, 84, 83], [7...</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[0, 1, 0], [0, 1, 0], [1, 3, 2], [2, 4, 3], ...</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[[49, 32, 24], [46, 32, 23], [43, 33, 21], [4...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[[28, 24, 23], [30, 26, 25], [32, 27, 24], [3...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-166e686f-9fc5-4eef-9b8d-3d9101159ece')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-166e686f-9fc5-4eef-9b8d-3d9101159ece button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-166e686f-9fc5-4eef-9b8d-3d9101159ece');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              Images  Ages\n",
              "0  [[[179, 149, 111], [184, 154, 116], [192, 162,...    57\n",
              "1  [[[85, 91, 91], [83, 89, 89], [80, 84, 83], [7...    50\n",
              "2  [[[0, 1, 0], [0, 1, 0], [1, 3, 2], [2, 4, 3], ...    69\n",
              "3  [[[49, 32, 24], [46, 32, 23], [43, 33, 21], [4...     8\n",
              "4  [[[28, 24, 23], [30, 26, 25], [32, 27, 24], [3...     8"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,6))\n",
        "plt.hist(df['Ages'],bins=100)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "qRrXdfLWHkCx",
        "outputId": "ddfdf527-1d95-436c-cf1a-ba2e14221c18"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "under_4=[]\n",
        "for i in range(len(df)):\n",
        "  if df['Ages'].iloc[i] <=4:\n",
        "    under_4.append(df.iloc[i])\n",
        "under_4=pd.DataFrame(under_4)\n",
        "under_4=under_4.sample(frac=0.3)\n",
        "\n",
        "up_4=df[df['Ages']>4]\n",
        "df=pd.concat([under_4,up_4])"
      ],
      "metadata": {
        "id": "K3OdnRAiHj_-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[df['Ages']<90]\n",
        "plt.figure(figsize=(18,6))\n",
        "plt.hist(df['Ages'],bins=89)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8Uicpx9BL3Ly",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "f838ccd0-021e-40b5-8670-63508d9d8dd2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "Y=[]\n",
        "for i in range(len(df)):\n",
        "  df['Images'].iloc[i]=cv2.resize(df['Images'].iloc[i],(width,height))\n",
        "  X.append(df['Images'].iloc[i])\n",
        "  Y.append(df['Ages'].iloc[i])\n",
        "\n",
        "X=np.array(X)\n",
        "Y=np.array(Y)"
      ],
      "metadata": {
        "id": "2QBTdoy5MEes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce775125-382b-45b2-af58-a1302f041aef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_val,y_train,y_val=train_test_split(X,Y,test_size=0.2)"
      ],
      "metadata": {
        "id": "2b11RrmnKQZ0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,x,y,transform=None):\n",
        "    super().__init__()\n",
        "    self.image = x\n",
        "    self.target = y\n",
        "    self.transform=transform\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    x = self.image[index]\n",
        "    y = self.target[index]\n",
        "    \n",
        "    if self.transform:\n",
        "      x = self.transform(x)\n",
        "\n",
        "    return x,y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image)"
      ],
      "metadata": {
        "id": "0lJV-9DrP-1W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "                                            torchvision.transforms.ToPILImage(),\n",
        "                                            torchvision.transforms.ToTensor(),\n",
        "                                            torchvision.transforms.RandomHorizontalFlip(),\n",
        "                                            torchvision.transforms.Normalize((0),(1))\n",
        "])\n",
        "\n",
        "dataset=CustomDataset(x_train,y_train,transform=transform)\n",
        "train_size=int(len(dataset)*0.8)\n",
        "val_size=len(dataset)-train_size\n",
        "train_data ,val_data = torch.utils.data.random_split(dataset,[train_size,val_size])\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_data_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "LPWOHiroKWAY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.cnn1 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "    self.cnn1_bn = nn.BatchNorm2d(32)\n",
        "    self.cnn2= nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1) \n",
        "    self.cnn2_bn = nn.BatchNorm2d(64)\n",
        "    self.cnn3 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1)\n",
        "    self.cnn3_bn = nn.BatchNorm2d(128)\n",
        "    self.cnn4= nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=1,padding=1) \n",
        "    self.cnn4_bn = nn.BatchNorm2d(256)\n",
        "\n",
        "    self.fc1= nn.Linear(50176,128)\n",
        "    self.fc2= nn.Linear(128,1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.cnn1(x)\n",
        "    x = self.cnn1_bn(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, kernel_size=(2,2))\n",
        "\n",
        "    x = self.cnn2(x)\n",
        "    x = self.cnn2_bn(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, kernel_size=(2,2))\n",
        "\n",
        "    x = self.cnn3(x)\n",
        "    x = self.cnn3_bn(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, kernel_size=(2,2))\n",
        "\n",
        "    x = self.cnn4(x)\n",
        "    x = self.cnn4_bn(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, kernel_size=(2,2))\n",
        "\n",
        "    x = torch.flatten(x, start_dim=1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = torch.dropout(x,0.3,train=True)\n",
        "    x = self.fc2(x)\n",
        "    # x = torch.softmax(x, dim=1)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "kYidjGfNOvRm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "model = Model()\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "iuSPJa7NWBtZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "loss_function = nn.MSELoss()"
      ],
      "metadata": {
        "id": "_nSOnSgqDrEs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_acc(preds,labels):\n",
        "  _,preds_max = torch.max(preds,1)\n",
        "  acc = torch.sum(preds_max == labels.data, dtype=torch.float64) / len(preds)\n",
        "  return acc"
      ],
      "metadata": {
        "id": "Qk7xBNBGL3u0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data_loader,epoch):\n",
        "  model.train(True)\n",
        "  train_loss=0\n",
        "  train_acc=0\n",
        "  for images,labels in tqdm(train_data_loader):\n",
        "    images=images.to(torch.float32)\n",
        "    labels=labels.to(torch.float32)\n",
        "    images=images.to(device)\n",
        "    labels=labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    preds_train = model(images)\n",
        "   \n",
        "    loss_train=loss_function(preds_train,labels) # loss_train\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss_train\n",
        "    train_acc += calc_acc(preds_train,labels)\n",
        "    \n",
        "  total_loss = train_loss/len(train_data_loader)\n",
        "  total_acc = train_acc/len(train_data_loader)\n",
        "  print(f\"loss_train:{total_loss},accuracy_train:{total_acc}\")\n"
      ],
      "metadata": {
        "id": "SKFhQUVNDV8S"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, val_data_loader,epoch):\n",
        "  model.eval()\n",
        "  test_loss=0.0\n",
        "  test_acc=0.0\n",
        "  for images,labels in tqdm(val_data_loader):    \n",
        "    images=images.to(device)\n",
        "    labels=labels.to(device)\n",
        "    \n",
        "    preds_test = model(images)\n",
        "\n",
        "    loss_test=loss_function(preds_test,labels) \n",
        "\n",
        "    test_loss += loss_test\n",
        "    test_acc += calc_acc(preds_test,labels)\n",
        "\n",
        "  total_loss = test_loss/len(val_data_loader)\n",
        "  total_acc = test_acc/len(val_data_loader)\n",
        "  print(f\"loss_eval:{total_loss},accuracy_eval:{total_acc}\")"
      ],
      "metadata": {
        "id": "5wlbb1GUEm3F"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f'Epoch:{epoch}')\n",
        "  train(model, train_data_loader, epoch)\n",
        "  test(model, val_data_loader, epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "MmIT0qsfEppV",
        "outputId": "68743470-23d0-4311-a7a0-329dd0965de2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/4714 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "100%|██████████| 4714/4714 [01:12<00:00, 65.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train:427.4591064453125,accuracy_train:0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 331/1179 [00:01<00:04, 207.42it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-59fc4eae8538>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch:{epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-6d66306e2ea5>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, val_data_loader, epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpreds_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-b4d37dee438b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn2_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2283\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2284\u001b[0m     )\n\u001b[1;32m   2285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.17 GiB total capacity; 10.56 GiB already allocated; 832.00 KiB free; 10.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/Face Age Regression/age_weight.pth\")"
      ],
      "metadata": {
        "id": "FKlUa96mEvge"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}